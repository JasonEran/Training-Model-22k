{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e31a1-3ebc-4a58-b7f4-b63819a123e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTX 5090 Optimized Training Script\n",
    "# Implements large-scale vision model training with cross-validation\n",
    "print(\"RTX 5090 Training Mode Activated!\")\n",
    "\n",
    "# Automatic dependency management\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"{package} installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"{package} installation complete\")\n",
    "\n",
    "# Check and install required dependencies\n",
    "required_packages = ['pandas', 'numpy', 'scikit-learn']\n",
    "print(\"Checking and installing required packages...\")\n",
    "for package in required_packages:\n",
    "    install_package(package)\n",
    "\n",
    "# Install deep learning frameworks\n",
    "try:\n",
    "    import fastai\n",
    "    print(\"fastai installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing fastai...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"fastai\"])\n",
    "    print(\"fastai installation complete\")\n",
    "\n",
    "try:\n",
    "    import timm\n",
    "    print(\"timm installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing timm...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"timm\"])\n",
    "    print(\"timm installation complete\")\n",
    "\n",
    "# Import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "\n",
    "# Configuration class\n",
    "class CFG:\n",
    "    # File paths\n",
    "    BASE_PATH = Path('./')\n",
    "    TRAIN_FEATURES_PATH = BASE_PATH / 'train_features.csv'\n",
    "    TRAIN_LABELS_PATH = BASE_PATH / 'train_labels.csv'\n",
    "    TEST_FEATURES_PATH = BASE_PATH / 'test_features.csv'\n",
    "    \n",
    "    # RTX 5090 optimized settings\n",
    "    MODEL_ARCHITECTURE = 'convnext_large_in22k'  # Upgraded to larger model\n",
    "    IMAGE_SIZE = 512      # Higher resolution\n",
    "    BATCH_SIZE = 32       # Optimized for RTX 5090\n",
    "    N_FOLDS = 5\n",
    "    EPOCHS = 15           # Moderate increase in training epochs\n",
    "    \n",
    "    # RTX 5090 optimization\n",
    "    NUM_WORKERS = 12      # Optimized threading\n",
    "    PIN_MEMORY = True\n",
    "    PREFETCH_FACTOR = 4\n",
    "    \n",
    "    # Competition settings\n",
    "    TARGET_COL = 'label'\n",
    "    SEED = 42\n",
    "    BASE_LR = 1e-3\n",
    "\n",
    "print(f\"RTX 5090 Configuration:\")\n",
    "print(f\"   Model: {CFG.MODEL_ARCHITECTURE}\")\n",
    "print(f\"   Resolution: {CFG.IMAGE_SIZE}x{CFG.IMAGE_SIZE}\")\n",
    "print(f\"   Batch Size: {CFG.BATCH_SIZE}\")\n",
    "print(f\"   Training Epochs: {CFG.EPOCHS}\")\n",
    "\n",
    "# RTX 5090 CUDA optimization settings\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Detected: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    print(\"RTX 5090 optimizations enabled\")\n",
    "    try:\n",
    "        test_tensor = torch.randn(100, 100).cuda()\n",
    "        result = torch.mm(test_tensor, test_tensor)\n",
    "        print(\"CUDA test passed!\")\n",
    "        del test_tensor, result\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        print(f\"CUDA test failed: {e}\")\n",
    "        print(\"Please check PyTorch CUDA installation!\")\n",
    "else:\n",
    "    print(\"CUDA unavailable, using CPU mode\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed(CFG.SEED, reproducible=True)\n",
    "\n",
    "# Data augmentation transforms\n",
    "def get_transforms():\n",
    "    return aug_transforms(\n",
    "        size=CFG.IMAGE_SIZE,\n",
    "        min_scale=0.7,\n",
    "        max_rotate=20,\n",
    "        max_lighting=0.4,\n",
    "        max_warp=0.25,\n",
    "        p_affine=0.9,\n",
    "        p_lighting=0.9\n",
    "    )\n",
    "\n",
    "# Data preparation\n",
    "print(\"\\nPreparing data...\")\n",
    "\n",
    "# Check if data files exist\n",
    "required_files = [CFG.TRAIN_FEATURES_PATH, CFG.TRAIN_LABELS_PATH, CFG.TEST_FEATURES_PATH]\n",
    "for file_path in required_files:\n",
    "    if not file_path.exists():\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        print(\"Please ensure the following files are in the current directory:\")\n",
    "        print(\"  - train_features.csv\")\n",
    "        print(\"  - train_labels.csv\")\n",
    "        print(\"  - test_features.csv\")\n",
    "        raise FileNotFoundError(f\"Missing required file: {file_path}\")\n",
    "\n",
    "train_features_df = pd.read_csv(CFG.TRAIN_FEATURES_PATH)\n",
    "train_labels_df = pd.read_csv(CFG.TRAIN_LABELS_PATH)\n",
    "test_features_df = pd.read_csv(CFG.TEST_FEATURES_PATH)\n",
    "\n",
    "# Process labels - convert one-hot to categorical\n",
    "train_labels_df['label'] = train_labels_df.iloc[:, 1:].idxmax(axis=1)\n",
    "df = train_features_df.merge(train_labels_df[['id', 'label']], on='id')\n",
    "\n",
    "# Create image paths\n",
    "df['image_path'] = df['filepath'].apply(lambda x: CFG.BASE_PATH / x)\n",
    "test_features_df['image_path'] = test_features_df['filepath'].apply(lambda x: CFG.BASE_PATH / x)\n",
    "\n",
    "print(f\"Data loaded successfully!\")\n",
    "print(f\"   Training images: {len(df)}\")\n",
    "print(f\"   Test images: {len(test_features_df)}\")\n",
    "print(f\"   Number of classes: {df['label'].nunique()}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# Cross-validation setup\n",
    "print(\"\\nSetting up StratifiedGroupKFold...\")\n",
    "df['fold'] = -1\n",
    "splitter = StratifiedGroupKFold(n_splits=CFG.N_FOLDS, shuffle=True, random_state=CFG.SEED)\n",
    "\n",
    "# Assign fold numbers\n",
    "for fold, (train_idx, val_idx) in enumerate(splitter.split(df, df['label'], groups=df['site'])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "print(\"Fold distribution:\")\n",
    "print(df.fold.value_counts())\n",
    "\n",
    "# Training loop\n",
    "print(f\"\\nStarting RTX 5090 Training - {CFG.N_FOLDS} Fold Cross Validation\")\n",
    "\n",
    "all_preds = []\n",
    "all_oof_preds = []\n",
    "fold_scores = []\n",
    "vocab = None\n",
    "\n",
    "for fold in range(CFG.N_FOLDS):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold} - RTX 5090 Training\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # Create fold splitter function\n",
    "    def get_splitter(fold_num):\n",
    "        def _inner(o):\n",
    "            val_mask = o['fold'] == fold_num\n",
    "            train_mask = o['fold'] != fold_num\n",
    "            return o.index[train_mask], o.index[val_mask]\n",
    "        return _inner\n",
    "\n",
    "    # DataBlock configuration\n",
    "    dblock = DataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock),\n",
    "        get_x=ColReader('image_path'),\n",
    "        get_y=ColReader(CFG.TARGET_COL),\n",
    "        splitter=get_splitter(fold),\n",
    "        item_tfms=Resize(CFG.IMAGE_SIZE, method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),\n",
    "        batch_tfms=[*get_transforms(), Normalize.from_stats(*imagenet_stats)]\n",
    "    )\n",
    "    \n",
    "    print(f\"Creating DataLoaders (batch size: {CFG.BATCH_SIZE})...\")\n",
    "    \n",
    "    try:\n",
    "        # Create DataLoaders with RTX 5090 optimizations\n",
    "        if torch.cuda.is_available():\n",
    "            dls = dblock.dataloaders(\n",
    "                df,\n",
    "                bs=CFG.BATCH_SIZE,\n",
    "                num_workers=CFG.NUM_WORKERS,\n",
    "                pin_memory=CFG.PIN_MEMORY,\n",
    "                prefetch_factor=CFG.PREFETCH_FACTOR\n",
    "            )\n",
    "        else:\n",
    "            dls = dblock.dataloaders(\n",
    "                df,\n",
    "                bs=16,\n",
    "                num_workers=4\n",
    "            )\n",
    "        \n",
    "        # Store vocabulary from first fold\n",
    "        if vocab is None:\n",
    "            vocab = dls.vocab\n",
    "            print(f\"Class vocabulary: {list(vocab)}\")\n",
    "\n",
    "        print(f\"Creating {CFG.MODEL_ARCHITECTURE} model...\")\n",
    "        \n",
    "        # Setup callbacks for training\n",
    "        cbs = [\n",
    "            EarlyStoppingCallback(monitor='valid_loss', patience=3),\n",
    "            SaveModelCallback(monitor='valid_loss', fname=f'best_model_fold_{fold}')\n",
    "        ]\n",
    "        \n",
    "        # Create learner with mixed precision\n",
    "        learn = vision_learner(\n",
    "            dls,\n",
    "            CFG.MODEL_ARCHITECTURE,\n",
    "            metrics=[error_rate, accuracy],\n",
    "            cbs=cbs\n",
    "        ).to_fp16()\n",
    "\n",
    "        print(f\"Starting training for {CFG.EPOCHS} epochs...\")\n",
    "        \n",
    "        # Find optimal learning rate\n",
    "        try:\n",
    "            lr_min, lr_steep = learn.lr_find()\n",
    "            print(f\"Suggested learning rate: {lr_steep:.2e}\")\n",
    "            final_lr = lr_steep\n",
    "        except:\n",
    "            print(\"Using default learning rate\")\n",
    "            final_lr = CFG.BASE_LR\n",
    "        \n",
    "        # Train the model\n",
    "        learn.fit_one_cycle(CFG.EPOCHS, lr_max=final_lr)\n",
    "        \n",
    "        # Record validation scores\n",
    "        val_results = learn.validate()\n",
    "        val_loss = float(val_results[0])\n",
    "        val_acc = float(val_results[2])  # accuracy is the 2nd metric\n",
    "        fold_scores.append({'fold': fold, 'val_loss': val_loss, 'val_acc': val_acc})\n",
    "        print(f\"Fold {fold} validation results: Loss={val_loss:.4f}, Acc={val_acc:.4f}\")\n",
    "\n",
    "        # Generate test predictions\n",
    "        print(\"Generating predictions...\")\n",
    "        test_dl = dls.test_dl(test_features_df)\n",
    "        preds, _ = learn.get_preds(dl=test_dl)\n",
    "        all_preds.append(preds)\n",
    "        \n",
    "        # Get out-of-fold predictions\n",
    "        val_dl = dls.valid\n",
    "        oof_preds, _ = learn.get_preds(dl=val_dl)\n",
    "        all_oof_preds.append(oof_preds)\n",
    "\n",
    "        # Memory cleanup\n",
    "        print(\"Memory cleanup...\")\n",
    "        del learn, dls, test_dl, val_dl\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Fold {fold} training error: {e}\")\n",
    "        print(\"Trying with reduced configuration...\")\n",
    "        \n",
    "        # Fallback configuration\n",
    "        dls = dblock.dataloaders(df, bs=16, num_workers=4)\n",
    "        if vocab is None:\n",
    "            vocab = dls.vocab\n",
    "            \n",
    "        learn = vision_learner(\n",
    "            dls,\n",
    "            CFG.MODEL_ARCHITECTURE,\n",
    "            metrics=[error_rate, accuracy],\n",
    "            cbs=[EarlyStoppingCallback(monitor='valid_loss', patience=3)]\n",
    "        )\n",
    "        \n",
    "        learn.fit_one_cycle(CFG.EPOCHS, lr_max=CFG.BASE_LR)\n",
    "        \n",
    "        val_results = learn.validate()\n",
    "        val_loss = float(val_results[0])\n",
    "        val_acc = float(val_results[2])\n",
    "        fold_scores.append({'fold': fold, 'val_loss': val_loss, 'val_acc': val_acc})\n",
    "        \n",
    "        test_dl = dls.test_dl(test_features_df)\n",
    "        preds, _ = learn.get_preds(dl=test_dl)\n",
    "        all_preds.append(preds)\n",
    "        \n",
    "        val_dl = dls.valid\n",
    "        oof_preds, _ = learn.get_preds(dl=val_dl)\n",
    "        all_oof_preds.append(oof_preds)\n",
    "        \n",
    "        del learn, dls, test_dl, val_dl\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"RTX 5090 Training Complete!\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Display fold results\n",
    "print(\"\\nCross-validation results:\")\n",
    "for score in fold_scores:\n",
    "    print(f\"Fold {score['fold']}: Loss={score['val_loss']:.4f}, Acc={score['val_acc']:.4f}\")\n",
    "\n",
    "avg_loss = np.mean([s['val_loss'] for s in fold_scores])\n",
    "avg_acc = np.mean([s['val_acc'] for s in fold_scores])\n",
    "print(f\"\\nAverage performance: Loss={avg_loss:.4f}, Acc={avg_acc:.4f}\")\n",
    "\n",
    "# Ensemble strategy - weighted by validation performance\n",
    "print(f\"\\nExecuting ensemble strategy...\")\n",
    "\n",
    "val_accs = [s['val_acc'] for s in fold_scores]\n",
    "weights = torch.softmax(torch.tensor(val_accs) * 5, dim=0)\n",
    "print(f\"Fold weights: {[f'{w:.3f}' for w in weights.tolist()]}\")\n",
    "\n",
    "# Weighted ensemble predictions\n",
    "ensemble_preds = sum(w * pred for w, pred in zip(weights, all_preds))\n",
    "\n",
    "# Create submission file\n",
    "print(\"\\nCreating submission file...\")\n",
    "\n",
    "submission_df = pd.DataFrame(columns=['id'] + list(vocab))\n",
    "submission_df['id'] = test_features_df['id']\n",
    "submission_df[list(vocab)] = ensemble_preds.numpy()\n",
    "\n",
    "# Save submission\n",
    "submission_df.to_csv('rtx5090_submission.csv', index=False)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"RTX 5090 Submission File Created!\")\n",
    "print(f\"{'='*50}\")\n",
    "print(\"=== Configuration Summary ===\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"Model: {CFG.MODEL_ARCHITECTURE}\")\n",
    "print(f\"Resolution: {CFG.IMAGE_SIZE}x{CFG.IMAGE_SIZE}\")\n",
    "print(f\"Batch Size: {CFG.BATCH_SIZE}\")\n",
    "print(f\"Total Training Epochs: {CFG.N_FOLDS * CFG.EPOCHS}\")\n",
    "print(f\"Average Validation Accuracy: {avg_acc:.4f}\")\n",
    "print(f\"Mixed Precision Training: {'Yes' if torch.cuda.is_available() else 'No'}\")\n",
    "print(\"\")\n",
    "print(\"Submission file: rtx5090_submission.csv\")\n",
    "print(\"Ready to dominate the competition!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
